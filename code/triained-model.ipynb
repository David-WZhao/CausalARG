{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2945de4a-5781-42a5-94bc-29f9aafead0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn import functional as F\n",
    "import sys\n",
    "torch.backends.cudnn.enabled = False\n",
    "class Causal_ARG(nn.Module):\n",
    "    def __init__(self, X_dim, G_dim, z1_dim, z2_dim, transfer_count, mechanism_count,\n",
    "                 antibiotic_count):\n",
    "        super(Causal_ARG, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            # (batch * 1 * 1576 * 23) -> (batch * 32 * 1537 * 20)\n",
    "            nn.Conv2d(1, 32, kernel_size=(40, 4), ),\n",
    "            nn.LeakyReLU(),\n",
    "            # (batch * 32 * 1537 * 20) -> (batch * 32 * 1533 * 19)\n",
    "            nn.MaxPool2d(kernel_size=(5, 2), stride=1),\n",
    "            # (batch * 32 * 1533 * 19) -> (batch * 64 * 1504 * 16)\n",
    "            nn.Conv2d(32, 64, kernel_size=(30, 4)),\n",
    "            nn.LeakyReLU(),\n",
    "            # (batch * 64 * 1504 * 16) -> (batch * 128 * 1475 * 13)\n",
    "            nn.Conv2d(64, 128, kernel_size=(30, 4)),\n",
    "            nn.LeakyReLU(),\n",
    "            # (batch * 128 * 1475 * 13) -> (batch * 128 * 1471 * 12)\n",
    "            nn.MaxPool2d(kernel_size=(5, 2), stride=1),\n",
    "            # (batch * 128 * 1471, 12) -> (batch * 256 * 1452 * 10)\n",
    "            nn.Conv2d(128, 256, kernel_size=(20, 3)),\n",
    "            nn.LeakyReLU(),\n",
    "            # (batch * 256 * 1452 * 10) -> (batch * 256 * 1433 * 8)\n",
    "            nn.Conv2d(256, 256, kernel_size=(20, 3)),\n",
    "            nn.LeakyReLU(),\n",
    "            # (batch * 256 * 1433 * 8) -> (batch * 256 * 1430 * 8)\n",
    "            nn.MaxPool2d(kernel_size=(4, 1), stride=1),\n",
    "            # (batch * 256 * 1430 * 8) -> (batch * 1 * 1411 * 6)\n",
    "            nn.Conv2d(256, 1, kernel_size=(20, 3)),\n",
    "            nn.LeakyReLU(),\n",
    "            # (batch * 1 * 1411 * 6) -> (batch * 1 * 1410 * 6)\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), stride=1)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8460, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, X_dim),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.gauus = Gauussion(X_dim + 3, G_dim)\n",
    "        self.hidden = Hidden(X_dim, G_dim, z1_dim, z2_dim)\n",
    "        self.causal = Causal(z1_dim + z2_dim, transfer_count, mechanism_count, antibiotic_count)\n",
    "\n",
    "    def forward(self, seq_map, transfer_label, mechanism_label, antibiotic_label):\n",
    "        x = self.feature(seq_map)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        transfer_label.unsqueeze(-1)\n",
    "        mechanism_label.unsqueeze(-1)\n",
    "        antibiotic_label.unsqueeze(-1)\n",
    "\n",
    "        labels = [transfer_label, mechanism_label, antibiotic_label]\n",
    "        labels = torch.cat(labels, dim=1)\n",
    "        mean_logvar1, mean_logvar2, mean_logvar3, mean_logvar4, prob, G = self.gauus(torch.cat((x, labels), dim=1))\n",
    "\n",
    "        z1, z2 = self.hidden(x, G)\n",
    "        hidden_representation = torch.cat((z1, z2), dim=1)\n",
    "\n",
    "        transfer_pre, mechanism_pre, antibiotic_pre = self.causal(hidden_representation)\n",
    "\n",
    "        # return transfer_pre, mechanism_pre, antibiotic_pre, mean_logvar1, mean_logvar2, mean_logvar3, mean_logvar4, prob\n",
    "        return transfer_pre, mechanism_pre, antibiotic_pre\n",
    "\n",
    "class Hidden(nn.Module):\n",
    "    def __init__(self, X_dim, G_dim, z1_dim, z2_dim):\n",
    "        super(Hidden, self).__init__()\n",
    "        self.concat_dim = X_dim + G_dim\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(self.concat_dim, self.concat_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.concat_dim, z1_dim),\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(G_dim, G_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(G_dim, z2_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, X, G):\n",
    "        input = torch.cat((X, G), dim=1)\n",
    "\n",
    "        z1 = self.hidden1(input)\n",
    "        z2 = self.hidden2(G)\n",
    "        return z1, z2\n",
    "\n",
    "\n",
    "class Causal(nn.Module):\n",
    "    def __init__(self, input_dim, transfer_count, mechanism_count, antibiotic_count):\n",
    "        super(Causal, self).__init__()\n",
    "        self.transfer_layer = nn.Linear(input_dim, transfer_count)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.mechanism_layer = nn.Linear(input_dim + transfer_count, mechanism_count)\n",
    "        self.antibiotic_layer = nn.Linear(input_dim + transfer_count + mechanism_count, antibiotic_count)\n",
    "\n",
    "    def forward(self, input):\n",
    "        transfer_pre = self.softmax(self.transfer_layer(input))\n",
    "        mechanism_pre = self.softmax(self.mechanism_layer(torch.cat((input, transfer_pre), dim=1)))\n",
    "        antibiotic_pre = self.softmax(self.antibiotic_layer(torch.cat((input, transfer_pre, mechanism_pre), dim=1)))\n",
    "\n",
    "        return transfer_pre, mechanism_pre, antibiotic_pre\n",
    "\n",
    "\n",
    "class Gauussion(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Gauussion, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.mean_logvar1 = nn.Linear(hidden_dim, 2 * hidden_dim)\n",
    "        self.mean_logvar2 = nn.Linear(hidden_dim, 2 * hidden_dim)\n",
    "        self.mean_logvar3 = nn.Linear(hidden_dim, 2 * hidden_dim)\n",
    "        self.mean_logvar4 = nn.Linear(hidden_dim, 2 * hidden_dim)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.prob = nn.Linear(hidden_dim, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.hidden(x)\n",
    "        mean_logvar1 = self.mean_logvar1(hidden)\n",
    "        mean_logvar2 = self.mean_logvar2(hidden)\n",
    "        mean_logvar3 = self.mean_logvar3(hidden)\n",
    "        mean_logvar4 = self.mean_logvar4(hidden)\n",
    "        prob = self.softmax(self.prob(hidden))\n",
    "        values = [0, 1, 2, 3]\n",
    "        g_list = []\n",
    "        mid = hidden.size()[1]\n",
    "        for i, pro in enumerate(prob):\n",
    "\n",
    "            value = random.choices(values, pro.tolist())[0]\n",
    "\n",
    "            if (value == 0):\n",
    "                g = mean_logvar1[i][:mid] + torch.rand_like(mean_logvar1[i][mid:]) * mean_logvar1[i][mid:]\n",
    "            elif (value == 1):\n",
    "                g = mean_logvar2[i][:mid] + torch.rand_like(mean_logvar2[i][mid:]) * mean_logvar2[i][mid:]\n",
    "            elif (value == 2):\n",
    "                g = mean_logvar3[i][:mid] + torch.rand_like(mean_logvar3[i][mid:]) * mean_logvar3[i][mid:]\n",
    "            else:\n",
    "                g = mean_logvar4[i][:mid] + torch.rand_like(mean_logvar4[i][mid:]) * mean_logvar4[i][mid:]\n",
    "\n",
    "            g_list.append(g)\n",
    "\n",
    "\n",
    "        final_g = torch.stack(g_list)\n",
    "        return mean_logvar1, mean_logvar2, mean_logvar3, mean_logvar4, prob, final_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d12e3aa3-c9f1-46b7-93ac-0942a1c32e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "import torch   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ca0d2faf-f676-462b-9b1d-073a9dc79dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Causal_ARG(64, 64, 64, 64, 2, 6, 15)\n",
    "model.load_state_dict(torch.load('./model0.pth',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6b38e51c-17a9-4a0f-b515-e97546d68ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Causal_ARG(\n",
       "  (feature): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(40, 4), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): MaxPool2d(kernel_size=(5, 2), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(30, 4), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Conv2d(64, 128, kernel_size=(30, 4), stride=(1, 1))\n",
       "    (6): LeakyReLU(negative_slope=0.01)\n",
       "    (7): MaxPool2d(kernel_size=(5, 2), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(20, 3), stride=(1, 1))\n",
       "    (9): LeakyReLU(negative_slope=0.01)\n",
       "    (10): Conv2d(256, 256, kernel_size=(20, 3), stride=(1, 1))\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "    (12): MaxPool2d(kernel_size=(4, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): Conv2d(256, 1, kernel_size=(20, 3), stride=(1, 1))\n",
       "    (14): LeakyReLU(negative_slope=0.01)\n",
       "    (15): MaxPool2d(kernel_size=(2, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=8460, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=64, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (gauus): Gauussion(\n",
       "    (hidden): Sequential(\n",
       "      (0): Linear(in_features=67, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (mean_logvar1): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (mean_logvar2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (mean_logvar3): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (mean_logvar4): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (prob): Linear(in_features=64, out_features=4, bias=True)\n",
       "  )\n",
       "  (hidden): Hidden(\n",
       "    (hidden1): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    )\n",
       "    (hidden2): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (causal): Causal(\n",
       "    (transfer_layer): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (mechanism_layer): Linear(in_features=130, out_features=6, bias=True)\n",
       "    (antibiotic_layer): Linear(in_features=136, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ec16e-c8ef-4ef7-be0e-13ceb5f50825",
   "metadata": {},
   "source": [
    "Input your protein sequence here\n",
    "\n",
    "The seq below is an example, you can modify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2a4971b2-72d3-45db-89ae-f21805c2c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=\"\"\"\n",
    "MLATLPLAVHASPQPLEQIKLSESQLSGRVGMIEMDLASGRTLTAWRADERFPMMSTFKV\n",
    "VLCGAVLARVDAGDEQLERKIHYRQQDLVDYSPVSEKHLADGMTVGELCAAAITMSDNSA\n",
    "ANLLLATVGGPAGLTAFLRQIGDNVTRLDRWETELNEALPGDARATTTPASMAATLRKLL\n",
    "TSQRLSARSQRQLLQWMVDDRVAGPLIRSVLPAGWFIADKTGAGERGARGIVALLGPNNK\n",
    "AERIVVIYLRDTPASMAERN\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b73e25fe-67df-4966-9991-b467fe279b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_lactam\n",
      "antibiotic inactivation\n",
      "acquired\n"
     ]
    }
   ],
   "source": [
    "used_anti_label = {'beta_lactam': 0, 'bacitracin': 1,'multidrug': 2,'macrolide-lincosamide-streptogramin': 3,'aminoglycoside': 4,\n",
    "                   'polymyxin': 5,'chloramphenicol': 6, 'tetracycline': 7,'fosfomycin': 8,'glycopeptide': 9,'quinolone': 10,\n",
    "                   'trimethoprim': 11, 'sulfonamide': 12, 'rifampin': 13,'others': 14}\n",
    "anti_list = list(used_anti_label.keys())  \n",
    "uesd_mech_label = {'antibiotic target protection': 0,  'antibiotic efflux': 1, 'antibiotic inactivation': 2, \n",
    "                   'antibiotic target alteration': 3,'antibiotic target replacement': 4, 'others': 5}\n",
    "uesd_transfer_label = {'intrinsic':0,'acquired':1}\n",
    "tranfer_list = list(uesd_transfer_label.keys())\n",
    "mech_list = list(uesd_mech_label.keys())\n",
    "anti_list,mech_list\n",
    "word_map = {'M':0, 'A':1,'E':2, 'P':3, 'V':4, 'L':5, 'S':6, 'K':7, 'D':8, 'I':9, 'R':10, 'F':11, 'T':12,'G':13, \n",
    "         'N':14, 'H':15, 'C':16, 'Q':17, 'Y':18, 'W':19, 'X':20, 'Z':21}\n",
    "seq_mat = []\n",
    "for w in seq:\n",
    "\n",
    "    seq_mat = []\n",
    "    for w in seq:\n",
    "        if w not in word_map:\n",
    "            word_map[w] = len(word_map)\n",
    "        one_hot = [0] * 23\n",
    "        one_hot[word_map[w]] = 1\n",
    "        seq_mat.append(one_hot)\n",
    "#     zero-padding\n",
    "    for i in range(len(seq_mat), 1576):\n",
    "        one_hot = [0] * 23\n",
    "        seq_mat.append(one_hot)\n",
    "\n",
    "seq_map = torch.tensor(seq_mat, dtype=torch.float32).view(-1, 1, 1576, 23)\n",
    "transfer_output, mechanism_output, antibiotic_output= model.forward(seq_map,\n",
    "                torch.full((1, 1), -1),torch.full((1, 1), -1),torch.full((1, 1), -1))\n",
    "\n",
    "index = np.argmax(antibiotic_output.detach().numpy(), axis = 1)\n",
    "print(anti_list[index[0]])\n",
    "mech_index = np.argmax(mechanism_output.detach().numpy(), axis = 1)\n",
    "print(mech_list[mech_index[0]])\n",
    "transfer_index = np.argmax(transfer_output.detach().numpy(), axis = 1)\n",
    "print(tranfer_list[transfer_index[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
